{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a633671",
   "metadata": {},
   "source": [
    "# Plantilla ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20114289",
   "metadata": {},
   "source": [
    "### Modelos Basicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3017bc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def model_test(x, y):\n",
    "    # Modelos\n",
    "    lr = LinearRegression()\n",
    "    r = Ridge()\n",
    "    l = Lasso()\n",
    "    en = ElasticNet()\n",
    "    br = BayesianRidge()\n",
    "    dt = DecisionTreeRegressor()\n",
    "    rf = RandomForestRegressor()\n",
    "    \n",
    "    models = [\n",
    "        lr, r, l, en, br, dt, rf,\n",
    "    ]\n",
    "    \n",
    "    model_names = [\n",
    "        \"Linear Regression\", \"Ridge\", \"Lasso\", \"Elastic Net\", \"Bayesian Ridge\",\n",
    "        \"Decision Tree\", \"Random Forest\", \n",
    "    ]\n",
    "    \n",
    "    # Listas para almacenar m√©tricas de rendimiento\n",
    "    r2_scores = []\n",
    "    mae_scores = []\n",
    "    \n",
    "    # Dividir los datos en conjunto de entrenamiento y prueba\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for model in models:\n",
    "        model.fit(x_train, y_train)  # Entrenar el modelo\n",
    "        predictions = model.predict(x_test)  # Realizar predicciones\n",
    "        r2_scores.append(np.round(r2_score(y_test, predictions) * 100, 2))  # Calcular R2\n",
    "        mae_scores.append(np.round(mean_absolute_error(y_test, predictions), 2))  # Calcular MAE\n",
    "    \n",
    "    # Combinar los resultados en un DataFrame\n",
    "    results = {\"Model\": model_names, \"R2 Score\": r2_scores, \"MAE\": mae_scores}\n",
    "    results = pd.DataFrame(results)\n",
    "    results = results.sort_values(by=\"R2 Score\", ascending=False)  # Ordenar por R2 Score\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9bd639",
   "metadata": {},
   "source": [
    "### Modelos avanzados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6430f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def model_test(x, y, use_cross_val=False, cv=5):\n",
    "    # Modelos\n",
    "    models = [\n",
    "        LinearRegression(),\n",
    "        Ridge(),\n",
    "        Lasso(),\n",
    "        ElasticNet(),\n",
    "        BayesianRidge(),\n",
    "        DecisionTreeRegressor(),\n",
    "        RandomForestRegressor(),\n",
    "        GradientBoostingRegressor(),\n",
    "        XGBRegressor(verbosity=0),\n",
    "        LGBMRegressor(),\n",
    "        CatBoostRegressor(verbose=0)\n",
    "    ]\n",
    "\n",
    "    model_names = [\n",
    "        \"Linear Regression\", \"Ridge\", \"Lasso\", \"Elastic Net\", \"Bayesian Ridge\",\n",
    "        \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\",\n",
    "        \"XGBoost\", \"LightGBM\", \"CatBoost\"\n",
    "    ]\n",
    "    \n",
    "    # M√©tricas\n",
    "    r2_scores = []\n",
    "    mae_scores = []\n",
    "    mse_scores = []\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "    \n",
    "    # Divisi√≥n\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for model in models:\n",
    "        if use_cross_val:\n",
    "            # Validaci√≥n cruzada para R2\n",
    "            r2 = cross_val_score(model, x, y, scoring='r2', cv=cv).mean()\n",
    "            mae = -cross_val_score(model, x, y, scoring='neg_mean_absolute_error', cv=cv).mean()\n",
    "            mse = -cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=cv).mean()\n",
    "            rmse = np.sqrt(mse)\n",
    "            # MAPE no est√° directamente en sklearn, as√≠ que se omite en CV\n",
    "            mape = np.nan\n",
    "        else:\n",
    "            model.fit(x_train, y_train)\n",
    "            predictions = model.predict(x_test)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "            mae = mean_absolute_error(y_test, predictions)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "        \n",
    "        r2_scores.append(np.round(r2 * 100, 2))\n",
    "        mae_scores.append(np.round(mae, 2))\n",
    "        mse_scores.append(np.round(mse, 2))\n",
    "        rmse_scores.append(np.round(rmse, 2))\n",
    "        mape_scores.append(np.round(mape * 100, 2) if not np.isnan(mape) else None)\n",
    "    \n",
    "    # Resultados\n",
    "    results = pd.DataFrame({\n",
    "        \"Model\": model_names,\n",
    "        \"R2 Score (%)\": r2_scores,\n",
    "        \"MAE\": mae_scores,\n",
    "        \"MSE\": mse_scores,\n",
    "        \"RMSE\": rmse_scores,\n",
    "        \"MAPE (%)\": mape_scores\n",
    "    })\n",
    "    \n",
    "    return results.sort_values(by=\"R2 Score (%)\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0003dbb3",
   "metadata": {},
   "source": [
    "### Modelos basicos + graficos de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1180ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "\n",
    "\n",
    "def model_test(x, y, use_cross_val=False, cv=5, plot=True):\n",
    "    models = [\n",
    "        LinearRegression(),\n",
    "        Ridge(),\n",
    "        Lasso(),\n",
    "        ElasticNet(),\n",
    "        BayesianRidge(),\n",
    "        DecisionTreeRegressor(),\n",
    "        RandomForestRegressor(),\n",
    "        GradientBoostingRegressor()\n",
    "    ]\n",
    "\n",
    "    model_names = [\n",
    "        \"Linear Regression\", \"Ridge\", \"Lasso\", \"Elastic Net\", \"Bayesian Ridge\",\n",
    "        \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\"\n",
    "    ]\n",
    "    \n",
    "    r2_scores = []\n",
    "    mae_scores = []\n",
    "    mse_scores = []\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for model in models:\n",
    "        if use_cross_val:\n",
    "            r2 = cross_val_score(model, x, y, scoring='r2', cv=cv).mean()\n",
    "            mae = -cross_val_score(model, x, y, scoring='neg_mean_absolute_error', cv=cv).mean()\n",
    "            mse = -cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=cv).mean()\n",
    "            rmse = np.sqrt(mse)\n",
    "            mape = np.nan\n",
    "        else:\n",
    "            model.fit(x_train, y_train)\n",
    "            predictions = model.predict(x_test)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "            mae = mean_absolute_error(y_test, predictions)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "        \n",
    "        r2_scores.append(np.round(r2 * 100, 2))\n",
    "        mae_scores.append(np.round(mae, 2))\n",
    "        mse_scores.append(np.round(mse, 2))\n",
    "        rmse_scores.append(np.round(rmse, 2))\n",
    "        mape_scores.append(np.round(mape * 100, 2) if not np.isnan(mape) else None)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        \"Model\": model_names,\n",
    "        \"R2 Score (%)\": r2_scores,\n",
    "        \"MAE\": mae_scores,\n",
    "        \"MSE\": mse_scores,\n",
    "        \"RMSE\": rmse_scores,\n",
    "        \"MAPE (%)\": mape_scores\n",
    "    }).sort_values(by=\"R2 Score (%)\", ascending=False)\n",
    "    \n",
    "    # üìä GR√ÅFICOS\n",
    "    if plot:\n",
    "        metrics_to_plot = [\"R2 Score (%)\", \"MAE\", \"RMSE\"]\n",
    "        if results[\"MAPE (%)\"].notna().all():\n",
    "            metrics_to_plot.append(\"MAPE (%)\")\n",
    "        \n",
    "        for metric in metrics_to_plot:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            sns.barplot(data=results, x=\"Model\", y=metric, palette=\"viridis\")\n",
    "            plt.title(f\"Model Comparison - {metric}\")\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb92abd8",
   "metadata": {},
   "source": [
    "### Modelos avanzados + graficos de barras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22e1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    mean_absolute_percentage_error\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, BayesianRidge\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "\n",
    "def model_test(x, y, use_cross_val=False, cv=5, plot=True):\n",
    "    models = [\n",
    "        LinearRegression(),\n",
    "        Ridge(),\n",
    "        Lasso(),\n",
    "        ElasticNet(),\n",
    "        BayesianRidge(),\n",
    "        DecisionTreeRegressor(),\n",
    "        RandomForestRegressor(),\n",
    "        GradientBoostingRegressor(),\n",
    "        XGBRegressor(verbosity=0),\n",
    "        LGBMRegressor(),\n",
    "        CatBoostRegressor(verbose=0)\n",
    "    ]\n",
    "\n",
    "    model_names = [\n",
    "        \"Linear Regression\", \"Ridge\", \"Lasso\", \"Elastic Net\", \"Bayesian Ridge\",\n",
    "        \"Decision Tree\", \"Random Forest\", \"Gradient Boosting\",\n",
    "        \"XGBoost\", \"LightGBM\", \"CatBoost\"\n",
    "    ]\n",
    "    \n",
    "    r2_scores = []\n",
    "    mae_scores = []\n",
    "    mse_scores = []\n",
    "    rmse_scores = []\n",
    "    mape_scores = []\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    for model in models:\n",
    "        if use_cross_val:\n",
    "            r2 = cross_val_score(model, x, y, scoring='r2', cv=cv).mean()\n",
    "            mae = -cross_val_score(model, x, y, scoring='neg_mean_absolute_error', cv=cv).mean()\n",
    "            mse = -cross_val_score(model, x, y, scoring='neg_mean_squared_error', cv=cv).mean()\n",
    "            rmse = np.sqrt(mse)\n",
    "            mape = np.nan  # No disponible en CV directo\n",
    "        else:\n",
    "            model.fit(x_train, y_train)\n",
    "            predictions = model.predict(x_test)\n",
    "            r2 = r2_score(y_test, predictions)\n",
    "            mae = mean_absolute_error(y_test, predictions)\n",
    "            mse = mean_squared_error(y_test, predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "        \n",
    "        r2_scores.append(np.round(r2 * 100, 2))\n",
    "        mae_scores.append(np.round(mae, 2))\n",
    "        mse_scores.append(np.round(mse, 2))\n",
    "        rmse_scores.append(np.round(rmse, 2))\n",
    "        mape_scores.append(np.round(mape * 100, 2) if not np.isnan(mape) else None)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        \"Model\": model_names,\n",
    "        \"R2 Score (%)\": r2_scores,\n",
    "        \"MAE\": mae_scores,\n",
    "        \"MSE\": mse_scores,\n",
    "        \"RMSE\": rmse_scores,\n",
    "        \"MAPE (%)\": mape_scores\n",
    "    }).sort_values(by=\"R2 Score (%)\", ascending=False)\n",
    "    \n",
    "    # üìä GR√ÅFICOS\n",
    "    if plot:\n",
    "        metrics_to_plot = [\"R2 Score (%)\", \"MAE\", \"RMSE\"]\n",
    "        if results[\"MAPE (%)\"].notna().all():\n",
    "            metrics_to_plot.append(\"MAPE (%)\")\n",
    "        \n",
    "        for metric in metrics_to_plot:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            sns.barplot(data=results, x=\"Model\", y=metric, palette=\"viridis\")\n",
    "            plt.title(f\"Model Comparison - {metric}\")\n",
    "            plt.xticks(rotation=45, ha=\"right\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a76149",
   "metadata": {},
   "source": [
    "## ¬øComo usar esta funci√≥n?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7567c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manera basica\n",
    "model_test(X,y)\n",
    "\n",
    "# Sin validaci√≥n cruzada\n",
    "results = model_test(X, y)\n",
    "\n",
    "# Con validaci√≥n cruzada (5 folds)\n",
    "results_cv = model_test(X, y, use_cross_val=True, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef68cb",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
